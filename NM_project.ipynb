{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ****GANs for Data Augmentation in Image Classification****"
      ],
      "metadata": {
        "id": "SobB8Q316Pdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the field of image classification, obtaining a large and diverse dataset is crucial for training robust machine learning models. However, real-world datasets are often limited, imbalanced, and lack the variety needed to train models effectively. This project aims to address the challenge of dataset limitations by leveraging Generative Adversarial Networks (GANs) to augment existing image datasets. The goal is to generate synthetic images that are indistinguishable from real images, thereby enhancing the datasetâ€™s size and diversity. This augmentation is expected to improve the accuracy and generalization ability of image classification models, especially in scenarios with limited or imbalanced data. The project will explore the effectiveness of GAN-generated images in augmenting datasets and their impact on the performance of classification algorithms. The ultimate objective is to develop a methodology that can be applied to various image classification tasks, ensuring models are trained on datasets that better represent the complexity of real-world visual data\n"
      ],
      "metadata": {
        "id": "vTjZGNC-58TF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9AqT8uui4AYk"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "X_train = np.expand_dims(X_train, axis=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y503tSsM4Fmd",
        "outputId": "4ff49294-80b3-45bb-b1a6-6259e8891382"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=100))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(784, activation='tanh'))\n",
        "    model.add(Reshape((28, 28, 1)))\n",
        "    noise = Input(shape=(100,))\n",
        "    img = model(noise)\n",
        "    return Model(noise, img)"
      ],
      "metadata": {
        "id": "C4VBuqRY4HYu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    img = Input(shape=(28, 28, 1))\n",
        "    validity = model(img)\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "kTpf1E464K7A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "VV8qJ92W4NBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the generator\n",
        "generator = build_generator()\n",
        "z = Input(shape=(100,))\n",
        "img = generator(z)"
      ],
      "metadata": {
        "id": "2gOed_GQ4RrP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "validity = discriminator(img)"
      ],
      "metadata": {
        "id": "DUXuTRLa4cW7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains the generator to fool the discriminator\n",
        "combined = Model(z, validity)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))"
      ],
      "metadata": {
        "id": "IJPcclSH4T2n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "    # Select a random half of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], 128)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    # Sample noise and generate a batch of new images\n",
        "    noise = np.random.normal(0, 1, (128, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and generated as zeros)\n",
        "    d_loss_real, d_acc_real = discriminator.train_on_batch(imgs, np.ones((128, 1)))\n",
        "    d_loss_fake, d_acc_fake = discriminator.train_on_batch(gen_imgs, np.zeros((128, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    d_acc = 0.5 * np.add(d_acc_real, d_acc_fake)\n",
        "\n",
        "    # Train the generator (wants discriminator to mistake images as real)\n",
        "    g_loss = combined.train_on_batch(noise, np.ones((128, 1)))\n",
        "\n",
        "    # If at save interval => save generated image samples and plot progress\n",
        "    if epoch % 1000 == 0:\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss, 100*d_acc, g_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX1XlZgf4Vb5",
        "outputId": "f13af040-aaa6-4d0a-a45d-6f3f5cb27e55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 7ms/step\n",
            "0 [D loss: 0.003639, acc.: 100.00%] [G loss: 7.131785]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTwf3OEk4lLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}